# -*- coding: utf-8 -*-
"""MRI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dqaP4M2SNqcVcWuH1rcclWfZOLma46fe
"""

# ==========================================
# PART 1 : EfficientNet + å¹¾ä½•ä¿ç•™ç­–ç•¥
# ==========================================
!pip install roboflow opencv-python matplotlib scikit-learn tensorflow seaborn

import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
from tensorflow.keras import mixed_precision
from sklearn.utils import class_weight
from roboflow import Roboflow

try:
    from google.colab import files
except ImportError:
    pass

# 0. æ¸…ç†èˆŠæ¨¡å‹èˆ‡ç’°å¢ƒ
tf.keras.backend.clear_session()
if os.path.exists('my_mri_model.h5'):
    os.remove('my_mri_model.h5')

# é–‹å•Ÿæ··åˆç²¾åº¦åŠ é€Ÿ (å ±å‘Šä¸­æåˆ°çš„ Mixed Precision)
mixed_precision.set_global_policy('mixed_float16')

# 1. ä¸‹è¼‰è³‡æ–™
rf = Roboflow(api_key="Fejkqw1NB22U2OhV41Ph")
project = rf.workspace("mri-l4mg5").project("mri-brain-tumor-nxio6")
version = project.version(2)
dataset = version.download("folder")

dataset_path = dataset.location
train_dir = os.path.join(dataset_path, "train")
valid_dir = os.path.join(dataset_path, "valid")

# 2. å½±åƒå‰è™•ç† (å ±å‘Šä¸­æåˆ°çš„ CLAHE æŠ€è¡“)
def report_preprocessing(img):
    img = img.astype('uint8')
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    # CLAHE: é™åˆ¶å°æ¯”åº¦è‡ªé©æ‡‰ç›´æ–¹åœ–å‡è¡¡åŒ–
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl,a,b))
    img_enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)
    return img_enhanced.astype('float32')

# 3. è³‡æ–™ç”Ÿæˆ (âš ï¸ é—œéµä¿®æ­£ï¼šå¹¾ä½•ä¿ç•™ç­–ç•¥)
# å°æ‡‰å ±å‘Šï¼šä¿®æ­£äº†éåº¦æ—‹è½‰å°è‡´ä½ç½®ç‰¹å¾µéºå¤±çš„å•é¡Œ
BATCH_SIZE = 16
IMG_SIZE = (224, 224)

train_datagen = ImageDataGenerator(
    preprocessing_function=report_preprocessing,
    # ğŸ”¥ ä¿®æ”¹é»ï¼šå°‡æ—‹è½‰èˆ‡ä½ç§»é™è‡³æ¥µä½ï¼Œåƒ…æ¨¡æ“¬äº›å¾®èª¤å·®
    rotation_range=2,        # å¾ 20 æ”¹ç‚º 2 (å¹¾ä¹ä¸æ—‹è½‰)
    width_shift_range=0.02,  # å¾ 0.1 æ”¹ç‚º 0.02
    height_shift_range=0.02, # å¾ 0.1 æ”¹ç‚º 0.02
    zoom_range=0.02,         # é™ä½ç¸®æ”¾å¹…åº¦
    brightness_range=[0.8, 1.2], # ä¿ç•™äº®åº¦è®ŠåŒ–ä»¥é©æ‡‰ä¸åŒæˆåƒæ¢ä»¶
    horizontal_flip=True,    # å·¦å³ç¿»è½‰æ˜¯è§£å‰–å­¸ä¸Šåˆç†çš„ (äººè…¦å°ç¨±)
    fill_mode='nearest',
    rescale=1./255
)

valid_datagen = ImageDataGenerator(
    preprocessing_function=report_preprocessing,
    rescale=1./255
)

train_generator = train_datagen.flow_from_directory(
    train_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')

valid_generator = valid_datagen.flow_from_directory(
    valid_dir, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode='categorical')

# 4. æ¬Šé‡è¨ˆç®— (å ±å‘Šä¸­æåˆ°çš„é¡åˆ¥ä¸å¹³è¡¡è™•ç†)
original_weights = class_weight.compute_class_weight(
    class_weight='balanced',
    classes=np.unique(train_generator.classes),
    y=train_generator.classes
)
class_weights_dict = dict(enumerate(original_weights))

# é‡å° Glioma çµ¦äºˆæ¬Šé‡åŠ æˆ (è§£æ±ºèª¤åˆ¤å•é¡Œ)
indices = train_generator.class_indices
glioma_idx = indices.get('glioma_tumor')
if glioma_idx is not None:
    class_weights_dict[glioma_idx] *= 2.0
    print(f"ğŸ”¥ å¯¦æ–½ Glioma æ¬Šé‡åŠ å¼·ç­–ç•¥: {class_weights_dict}")

# 5. å»ºç«‹æ¨¡å‹ (å ±å‘Šä¸­æåˆ°çš„ EfficientNetB0 æ¶æ§‹)
# include_top=False: ç§»é™¤åŸåˆ†é¡å±¤
base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))

# ğŸ”¥ å…¨æ¨¡å‹è§£é– (Full Unfreeze)ï¼šé©æ‡‰ MRI ç‰¹æ®Šç´‹ç†
base_model.trainable = True

x = base_model.output
x = GlobalAveragePooling2D()(x) # å ±å‘Šæåˆ°çš„ GAP å±¤

# å ±å‘Šæåˆ°çš„åˆ†é¡é ­è¨­è¨ˆ (Dense + BN + Dropout)
x = BatchNormalization()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)

x = BatchNormalization()(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.4)(x)

predictions = Dense(train_generator.num_classes, activation='softmax', dtype='float32')(x)

model = Model(inputs=base_model.input, outputs=predictions)

# 6. ç·¨è­¯è¨­å®š (å ±å‘Šä¸­æåˆ°çš„æ¥µä½å­¸ç¿’ç‡ç­–ç•¥)
model.compile(optimizer=Adam(learning_rate=1e-5), # 1e-5 = 0.00001
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 7. è¨“ç·´è¨­å®š
checkpoint = ModelCheckpoint('my_mri_model.h5',
                             monitor='val_accuracy',
                             save_best_only=True,
                             verbose=1)

early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)
reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)

print("ğŸš€ å•Ÿå‹• EfficientNet å…¨åŸŸå¾®èª¿ (å¹¾ä½•ä¿ç•™æ¨¡å¼)...")

history = model.fit(
    train_generator,
    epochs=40,
    validation_data=valid_generator,
    class_weight=class_weights_dict,
    callbacks=[early_stop, reduce_lr, checkpoint]
)

print("\nâœ… è¨“ç·´å®Œæˆï¼æ¨¡å‹å·²ç¬¦åˆå ±å‘Šæ‰€è¿°ä¹‹å¹¾ä½•ä¿ç•™ç­–ç•¥ã€‚")
try:
    files.download('my_mri_model.h5')
except:
    pass

# ==========================================
# PART 2 (æ¸¬è©¦)
# ==========================================
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from google.colab import files
import math

# 1. å®šç¾©å½±åƒå‰è™•ç† (å¿…é ˆèˆ‡è¨“ç·´æ™‚ä¸€æ¨¡ä¸€æ¨£)
def report_preprocessing(img):
    img = img.astype('uint8')
    lab = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)
    l, a, b = cv2.split(lab)
    # é€™è£¡ç¶­æŒ 2.0ï¼Œå› ç‚ºé€™æ˜¯æ‚¨å‰›æ‰ EfficientNet ç”¨çš„åƒæ•¸
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    cl = clahe.apply(l)
    limg = cv2.merge((cl,a,b))
    img_enhanced = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)
    return img_enhanced.astype('float32')

# 2. è¼‰å…¥æ¨¡å‹
print("ğŸ”„ æ­£åœ¨è®€å–æ¨¡å‹ 'my_mri_model.h5' ...")

if not os.path.exists('my_mri_model.h5'):
    print("âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆï¼è«‹ç¢ºèª Part 1 æ˜¯å¦å·²è·‘å®Œä¸¦å­˜æª”ã€‚")
else:
    # è¼‰å…¥æ¨¡å‹ (éœ€å‚³å…¥è‡ªå®šç¾©å‡½æ•¸)
    model = load_model('my_mri_model.h5', custom_objects={'report_preprocessing': report_preprocessing})
    print("âœ… æ¨¡å‹è¼‰å…¥æˆåŠŸï¼")

    # å®šç¾©é¡åˆ¥ (Roboflow é è¨­æ’åº)
    class_labels = ['glioma', 'meningioma', 'notumor', 'pituitary']

    print("\n" + "="*40)
    print("ã€ æ­¥é©Ÿ 1 ã€‘è«‹ä¸Šå‚³ä¸€æ‰¹ã€ŒåŒä¸€ç¨®é¡åˆ¥ã€çš„ç…§ç‰‡")
    print("="*40)
    uploaded = files.upload()

    # å¦‚æœæœ‰ä¸Šå‚³æª”æ¡ˆ
    if len(uploaded) > 0:
        num_files = len(uploaded)

        # 3. è©¢å•ä½¿ç”¨è€…æ­£ç¢ºç­”æ¡ˆ
        print("\n" + "="*40)
        print("ã€ æ­¥é©Ÿ 2 ã€‘è«‹å‘Šè¨´æˆ‘é€™æ‰¹ç…§ç‰‡çš„æ­£ç¢ºç­”æ¡ˆæ˜¯èª°ï¼Ÿ")
        print(f" 0 : {class_labels[0]} (ç¥ç¶“è† è³ªç˜¤)")
        print(f" 1 : {class_labels[1]} (è…¦è†œç˜¤)")
        print(f" 2 : {class_labels[2]} (ç„¡è…«ç˜¤)")
        print(f" 3 : {class_labels[3]} (å‚é«”ç˜¤)")
        print("="*40)

        while True:
            try:
                true_idx = int(input(f"è«‹è¼¸å…¥æ­£ç¢ºé¡åˆ¥çš„ç·¨è™Ÿ (0-3): "))
                if 0 <= true_idx <= 3:
                    true_label_name = class_labels[true_idx]
                    break
                else:
                    print("âš ï¸ è«‹è¼¸å…¥ 0 åˆ° 3 ä¹‹é–“çš„æ•¸å­—ï¼")
            except ValueError:
                print("âš ï¸ è«‹è¼¸å…¥æ•¸å­—ï¼")

        print(f"\nğŸš€ æ”¶åˆ°ï¼æ­£åœ¨ä»¥ã€Œ{true_label_name}ã€ç‚ºæ¨™æº–é€²è¡Œæ‰¹æ¬¡è©•åˆ†...\n")

        # 4. é–‹å§‹æ‰¹æ¬¡é æ¸¬
        correct_count = 0
        cols = 3
        rows = math.ceil(num_files / cols)
        plt.figure(figsize=(15, 5 * rows))

        for i, fn in enumerate(uploaded.keys()):
            # A. è®€å–
            ax = plt.subplot(rows, cols, i + 1)
            img = load_img(fn, target_size=(224, 224))

            # B. é è™•ç†èˆ‡é æ¸¬
            x = img_to_array(img)
            x = report_preprocessing(x)
            x = np.expand_dims(x, axis=0)
            x = x / 255.0 # EfficientNet è¨“ç·´æ™‚è‹¥æœ‰ rescaleï¼Œé€™è£¡ä¹Ÿè¦æœ‰

            pred = model.predict(x, verbose=0)
            result_idx = np.argmax(pred[0])
            result_label = class_labels[result_idx]
            confidence = np.max(pred[0]) * 100

            # C. åˆ¤æ–·å°éŒ¯
            is_correct = (result_idx == true_idx)
            if is_correct:
                correct_count += 1
                status_color = 'green'
                status_icon = 'âœ…'
            else:
                status_color = 'red'
                status_icon = 'âŒ'

            # D. ç¹ªåœ–èˆ‡æ¨™ç¤º
            plt.imshow(img)
            plt.axis('off')

            # æ¨™é¡Œé¡¯ç¤ºï¼šé æ¸¬çµæœ (ä¿¡å¿ƒåº¦)
            # å¦‚æœéŒ¯äº†ï¼Œæœƒæ‹¬è™Ÿé¡¯ç¤ºæ­£ç¢ºç­”æ¡ˆ
            if is_correct:
                title_text = f"{status_icon} Pred: {result_label}\nConf: {confidence:.1f}%"
            else:
                title_text = f"{status_icon} Pred: {result_label}\n(True: {true_label_name})\nConf: {confidence:.1f}%"

            plt.title(title_text, color=status_color, fontsize=12, fontweight='bold')

        plt.tight_layout()
        plt.show()

        # 5. æœ€çµ‚çµç®—å ±å‘Š
        accuracy = (correct_count / num_files) * 100
        print("\n" + "="*40)
        print(f"ğŸ“Š æ¸¬è©¦å ±å‘Š (Ground Truth: {true_label_name})")
        print("-" * 40)
        print(f"ç¸½å¼µæ•¸    : {num_files}")
        print(f"ç­”å°å¼µæ•¸  : {correct_count}")
        print(f"ç­”éŒ¯å¼µæ•¸  : {num_files - correct_count}")
        print("-" * 40)
        print(f"ğŸ† æœ¬æ¬¡æº–ç¢ºç‡ : {accuracy:.2f}%")
        print("="*40)

    else:
        print("âš ï¸ ä½ æ²’æœ‰é¸æ“‡ä»»ä½•æª”æ¡ˆå–”ï¼")